{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e34294-5e67-4f30-87ad-fa01b7c3cd6a",
   "metadata": {},
   "source": [
    "# Integrated Gradients\n",
    "入力特徴量の各寄与度を積分により計算する手法  \n",
    "baselineと実際の入力の間を積分して、各特徴量の寄与度を求める  \n",
    "各入力要素が予測にどの程度影響しているかのスコアが得られ、数値的に解釈できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a29697e-f206-4be6-875d-8a4489c053c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Final loss: 0.8066921234130859\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# シード固定\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# サンプルデータ生成（回帰タスク： y = 3*x + 2 にノイズ）\n",
    "X = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y = 3 * X + 2 + np.random.normal(0, 1, X.shape)\n",
    "\n",
    "# NumPy → Tensor\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# シンプルなMLPモデル\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, hidden_size=16):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleMLP(hidden_size=16)\n",
    "\n",
    "# 簡単な訓練（ここでは数エポックのみ）\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(X_tensor)\n",
    "    loss = criterion(preds, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Training completed. Final loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde58449-6c3a-4d44-9f2f-ed0c3955d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions: [[2.74365663]]\n",
      "Convergence Delta: [-0.00064946]\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# モデルを評価モードに\n",
    "model.eval()\n",
    "\n",
    "# Integrated Gradientsのインスタンス作成\n",
    "ig = IntegratedGradients(model)\n",
    "\n",
    "# 対象となるサンプル（例として、サンプルインデックス10）\n",
    "input_tensor = X_tensor[10:11]  # バッチサイズ1にする\n",
    "baseline = torch.zeros_like(input_tensor)  # baselineとしてゼロベクトルを使用\n",
    "\n",
    "# 属性（各特徴量の寄与度）の計算\n",
    "attributions, delta = ig.attribute(input_tensor, baseline, target=0, return_convergence_delta=True)\n",
    "\n",
    "print(\"Attributions:\", attributions.numpy())\n",
    "print(\"Convergence Delta:\", delta.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
