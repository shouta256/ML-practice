{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "210423b7-7b49-42e1-8cd0-e432062fd053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d7b03-cdda-4b4c-85a2-5080dda466f4",
   "metadata": {},
   "source": [
    "# 活性化関数とその微分\n",
    "## ReLU関数\n",
    "定義\n",
    "入力が0以下なら0、0より大きいならそのままの数値を返す\n",
    "## ReLUの微分\n",
    "定義\n",
    "入力が正の領域では勾配1、0以下では勾配0となる\n",
    "用途\n",
    "逆伝播において、誤差を隠れ層へ伝播する際に使用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f29109e-91d8-4a79-bb5a-263f049ac45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    # xが0より大きい部分は1、そうでなければ0を返す\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dfef8b-b712-4a7e-bca3-d058c3d96524",
   "metadata": {},
   "source": [
    "# 損失関数\n",
    "定義\n",
    "予測値 y_predと正解値yとの差の二乗の平均を計算する\n",
    "用途\n",
    "回帰問題において、モデルの出力と実際の値との差を定量的に評価し、学習の指標とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51eda685-8daa-46df-859d-c0208ba533c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数：平均二乗誤差 (MSE)\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe4fed-8d08-48fa-bac0-2f11580e2a3a",
   "metadata": {},
   "source": [
    "# 2層ニューラルネットワークの実装\n",
    "## 初期化(__init__)\n",
    "重み(W1,W2)の初期化  \n",
    "入力層 → 隠れ層、隠れ層 → 出力層への線形変換に必要な重みを乱数で初期化することで、学習開始時の対称性を防止し、効率的な学習を促す  \n",
    "バイアス(b1,b2)の初期化  \n",
    "重みと同様に、各層のバイアス項をゼロに初期化する  \n",
    "## 順伝播(forward)\n",
    "### 隠れ層の計算  \n",
    "線形結合：z1 = X・W1+b1  \n",
    "ReLU活性化：a1 = ReLU(z1)　非線形性を与えて、より複雑な関数を近似できるようにする  \n",
    "### 出力層の計算  \n",
    "線形結合のみ：z2 = a1・W2+b2　回帰問題の場合は、活性化関数を適用せずそのまま出力を返す  \n",
    "## 逆伝播(backward)\n",
    "### 出力層の誤差計算  \n",
    "誤差：error_output = y_pred - y　損失関数の微分として、出力層での誤差を求める  \n",
    "### 出力層のパラメータ勾配  \n",
    "重みの勾配：dW2 = a1  \n",
    "バイアスの勾配：db2 = np.sum(error_output, axis=0, keepdims=True)  \n",
    "### 隠れ層の誤差\n",
    "error_hidden = np.dot(error_output, self.W2.T) * relu_deriv(self.z1)  \n",
    "出力層からの誤差を隠れ層に伝播し、ReLUの微分をかけることで各ニューロンの勾配を求める\n",
    "### 隠れ層の勾配\n",
    "重みの勾配：dW1 = np.dot(X.T, error_hidden)  \n",
    "バイアスの勾配：db1 = np.sum(error_hidden, axis=0, keepdims=True)  \n",
    "### パラメータ更新\n",
    "各パラメータは、計算された勾配に学習率をかけた値を引く(勾配降下法)ことで更新する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3fa4d3d-8058-4935-875a-aba697e41175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # 重みの初期化（乱数）\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # 1層目の線形結合とReLUによる活性化\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = relu(self.z1)\n",
    "        # 2層目（出力層）の線形結合（今回は活性化関数なし）\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        # 出力をそのまま返す（回帰の場合）\n",
    "        return self.z2\n",
    "    \n",
    "    def backward(self, X, y, y_pred, learning_rate):\n",
    "        # 出力層の誤差\n",
    "        error_output = y_pred - y  # (バッチサイズ, output_size)\n",
    "        # 隠れ層から出力層への勾配\n",
    "        dW2 = np.dot(self.a1.T, error_output)\n",
    "        db2 = np.sum(error_output, axis=0, keepdims=True)\n",
    "        \n",
    "        # 隠れ層の誤差（ReLUの微分を乗算）\n",
    "        error_hidden = np.dot(error_output, self.W2.T) * relu_deriv(self.z1)\n",
    "        # 入力層から隠れ層への勾配\n",
    "        dW1 = np.dot(X.T, error_hidden)\n",
    "        db1 = np.sum(error_hidden, axis=0, keepdims=True)\n",
    "        \n",
    "        # パラメータの更新\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0a88e-ea85-458c-ac3c-ac270af0778c",
   "metadata": {},
   "source": [
    "# 学習ループ\n",
    "## エポック数\n",
    "1000回の学習ループを回して、ネットワークがデータに適合するようにパラメータを更新する\n",
    "## 順伝播と損失計算\n",
    "各エポックで入力データをネットワークに通し、予測値を得たあと、MSE損失を計算する\n",
    "## 逆伝播\n",
    "損失に基づいてパラメータの勾配を計算し、学習率に応じてパラメータを更新する　　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d3e2d81-c862-498d-a696-786b55ff28f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 10.1670\n",
      "Epoch 100, Loss: 0.0126\n",
      "Epoch 200, Loss: 0.0112\n",
      "Epoch 300, Loss: 0.0105\n",
      "Epoch 400, Loss: 0.0101\n",
      "Epoch 500, Loss: 0.0098\n",
      "Epoch 600, Loss: 0.0096\n",
      "Epoch 700, Loss: 0.0094\n",
      "Epoch 800, Loss: 0.0093\n",
      "Epoch 900, Loss: 0.0092\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ダミーデータの作成（例：入力2次元、出力1次元）\n",
    "    np.random.seed(0)\n",
    "    X = np.random.randn(100, 2)\n",
    "    # 簡単な線形関係にノイズを加えたもの\n",
    "    y = np.dot(X, np.array([[2], [-3]])) + 1 + 0.1 * np.random.randn(100, 1)\n",
    "    \n",
    "    # ネットワークの初期化\n",
    "    nn = NN(input_size=2, hidden_size=5, output_size=1)\n",
    "    \n",
    "    # 学習ループ\n",
    "    epochs = 1000\n",
    "    learning_rate = 0.001\n",
    "    for epoch in range(epochs):\n",
    "        # 順伝播\n",
    "        y_pred = nn.forward(X)\n",
    "        # 損失計算\n",
    "        loss = mse_loss(y, y_pred)\n",
    "        # 逆伝播\n",
    "        nn.backward(X, y, y_pred, learning_rate)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20000b-a2d2-4be6-ad9c-a41707bd4572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
